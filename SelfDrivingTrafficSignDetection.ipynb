{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00639790-3c60-4f66-9ec3-25d4ee17eaec",
      "metadata": {
        "id": "00639790-3c60-4f66-9ec3-25d4ee17eaec"
      },
      "source": [
        "# Self Driving Traffic Sign Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f876881-edf5-4099-8be5-d34a393877a8",
      "metadata": {
        "id": "8f876881-edf5-4099-8be5-d34a393877a8"
      },
      "source": [
        "Isaiah Jenkins"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0dcbf3-c303-49ec-8187-7b44990b1ece",
      "metadata": {
        "id": "bb0dcbf3-c303-49ec-8187-7b44990b1ece"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "012b37ac-9efb-417e-a169-9011d90a605a",
      "metadata": {
        "id": "012b37ac-9efb-417e-a169-9011d90a605a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f0a8fe-01b0-4928-beba-1d32baf1ece0",
      "metadata": {
        "id": "95f0a8fe-01b0-4928-beba-1d32baf1ece0"
      },
      "source": [
        "## 1. About the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "244d7748-5cd9-42ef-87bb-fe8ec7e2d567",
      "metadata": {
        "id": "244d7748-5cd9-42ef-87bb-fe8ec7e2d567"
      },
      "source": [
        "1. a. Description\n",
        "\n",
        "Throughout this analysis we will explore Udacity's Self Driving dataset. This dataset consists of images for thousands of pedestrians, bikers, cars, and traffic lights. Although traffic light images are underrepresented in the dataset, the focus of the analysis will be based solely on traffic light images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574bbf2e-d81b-458b-a2b1-ad6ecf906910",
      "metadata": {
        "id": "574bbf2e-d81b-458b-a2b1-ad6ecf906910"
      },
      "source": [
        "1. b. Data dictionary, 97,942 labels across 11 classes and 15,000 images, 1,720 null examples (images with no labels).\n",
        "\n",
        "Class Balance across images (labels in each image)\n",
        "\n",
        "* car - 64,399 - over represented\n",
        "* pedestrian - 10,806\n",
        "* trafficLight-Red - 6,870\n",
        "* trafficLight-Green - 5,465 - under represented\n",
        "* truck - 3,623 - under represented\n",
        "* trafficLight - 2,568 - under represented\n",
        "* biker - 1,864 - under represented\n",
        "* trafficLight-RedLeft - 1,751 - under represented\n",
        "* trafficLight-GreenLeft - 310 - under represented\n",
        "* trafficLight-Yellow - 272 - under represented\n",
        "* trafficLight-YellowLeft - 14 - under represented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ba6629-daed-4c51-bd9f-dcea2b5d31f1",
      "metadata": {
        "id": "a3ba6629-daed-4c51-bd9f-dcea2b5d31f1"
      },
      "source": [
        "## 2. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "573536a5-7aa4-4a25-bcb8-b076bafa5eb3",
      "metadata": {
        "id": "573536a5-7aa4-4a25-bcb8-b076bafa5eb3"
      },
      "source": [
        "Throughout this analysis, we will explore and build various deep learning convolutional neural network (CNN) architectures to detect traffic light signs, aiming to optimize accuracy and efficiency. Our objective is to compare different model variations, such as CNNs with different depths, pre-trained models, and data augmentation techniques, to determine the most effective approach. Potential challenges include handling variations in lighting conditions, occlusions, and small object sizes, which may impact detection performance. Additionally, dataset imbalances and misclassifications due to similar-looking traffic signs could introduce biases, requiring careful preprocessing and model tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70704988-df5d-414e-bb7b-a6e2ce582de2",
      "metadata": {
        "id": "70704988-df5d-414e-bb7b-a6e2ce582de2"
      },
      "source": [
        "## 3. Data Exploration, Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb591fe-c7b6-40ae-904c-a265459646e7",
      "metadata": {
        "id": "8fb591fe-c7b6-40ae-904c-a265459646e7"
      },
      "source": [
        "* Extract traffic sign & traffic light images from the dataset to help with computational efficiency.\n",
        "* Resize images to standardize dataset making it computationally efficient making it easier to analyze data.\n",
        "* Normalize pixel values (0-1 range) to help with generalization.\n",
        "* Augment data (rotation, brightness shifts, contrast changes) to improve generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b7ec18e-6c27-4948-b9a7-bf600e68ae78",
      "metadata": {
        "id": "4b7ec18e-6c27-4948-b9a7-bf600e68ae78"
      },
      "source": [
        "### Load in data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "!unzip -o -q '/content/gdrive/MyDrive/data.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "vx6mG2FtnLqI",
        "outputId": "34dc7e56-7e01-4b8c-fb05-06d8a85aca42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vx6mG2FtnLqI",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ca496251-ff93-4235-bffe-faef1cb98d4d",
      "metadata": {
        "id": "ca496251-ff93-4235-bffe-faef1cb98d4d"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = 'data/export'\n",
        "CSV_PATH = os.path.join(DATASET_PATH, '_annotations.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2f534363-2f7b-48d3-937d-2fa7a2c45a28",
      "metadata": {
        "id": "2f534363-2f7b-48d3-937d-2fa7a2c45a28"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(CSV_PATH) # load annotations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['class'].isin(['trafficLight-Red', 'trafficLight_Yellow', 'trafficLight-Green', 'pedestrain', 'biker'])]"
      ],
      "metadata": {
        "id": "k0-Aze907oI8"
      },
      "id": "k0-Aze907oI8",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ada1423d-de74-4699-9fd5-3d367983a643",
      "metadata": {
        "id": "ada1423d-de74-4699-9fd5-3d367983a643"
      },
      "outputs": [],
      "source": [
        "file_names = df['filename'].values # image files names\n",
        "labels = df['class'].values # classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "12586dcf-485e-4106-ae65-223e7f0d2998",
      "metadata": {
        "id": "12586dcf-485e-4106-ae65-223e7f0d2998"
      },
      "outputs": [],
      "source": [
        "label_map = {\"trafficLight-Red\": 0, \"trafficLight_Yellow\": 1, \"trafficLight-Green\": 2, }  # Adjust based on dataset\n",
        "labels = [label_map[label] for label in labels if label in label_map]  # Convert text labels to integers\n",
        "labels = to_categorical(labels, num_classes=3)  # Convert to one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Data into Train (80%) and Test (20%)\n",
        "train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "    file_names, labels, test_size=0.2, random_state=42, stratify=labels, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "t2j27DiCJ6Wo",
        "outputId": "2cd33a39-3212-44ef-9dde-a6938bc4605b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "id": "t2j27DiCJ6Wo",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [28215, 24511]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0eb3cf93815f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Split Data into Train (80%) and Test (20%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_files, test_files, train_labels, test_labels = train_test_split(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfile_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2848\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [28215, 24511]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f26a31-6e7e-49b1-b097-0a727da54e8b",
      "metadata": {
        "id": "04f26a31-6e7e-49b1-b097-0a727da54e8b"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7697debe-3e67-4398-9cd9-d17b10ab1368",
      "metadata": {
        "id": "7697debe-3e67-4398-9cd9-d17b10ab1368"
      },
      "outputs": [],
      "source": [
        "# Function to Load & Preprocess Images\n",
        "def load_and_preprocess_image(file_name, label):\n",
        "    img_path = os.path.join(DATASET_PATH, file_name)  # Update image folder path\n",
        "    img = load_img(img_path, target_size=IMG_SIZE)  # Load & Resize Image\n",
        "    img = img_to_array(img) / 255.0  # Convert to NumPy array & Normalize (0-1)\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d4c61e-4129-4780-a0fe-20b0f962c868",
      "metadata": {
        "id": "c6d4c61e-4129-4780-a0fe-20b0f962c868"
      },
      "outputs": [],
      "source": [
        "# Create Generators for Train & Test Data\n",
        "def data_generator(file_list, label_list):\n",
        "    for f, l in zip(file_list, label_list):\n",
        "        yield load_and_preprocess_image(f, l)  # Load one image at a time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10"
      ],
      "metadata": {
        "id": "jopWUlOEL1M9"
      },
      "id": "jopWUlOEL1M9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tf.data.Dataset that Loads Images on Demand\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(train_files, train_labels),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),  # Image Shape\n",
        "        tf.TensorSpec(shape=(3,), dtype=tf.float32)  # One-hot Encoded Label\n",
        "    )\n",
        ").batch(BATCH_SIZE).shuffle(1000).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(test_files, test _labels),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),  # Image Shape\n",
        "        tf.TensorSpec(shape=(3,), dtype=tf.float32)  # One-hot Encoded Label\n",
        "    )\n",
        ").batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "d_1jzFPb0an0"
      },
      "id": "d_1jzFPb0an0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview a Small Batch\n",
        "for img_batch, label_batch in dataset.take(1):\n",
        "    print(f\"Image Batch Shape: {img_batch.shape}\")\n",
        "    print(f\"Label Batch Shape: {label_batch.shape}\")"
      ],
      "metadata": {
        "id": "RV0fh5wH1rcS",
        "outputId": "5c852c82-04f5-4a1b-87d9-5b02ce72c97e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RV0fh5wH1rcS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Batch Shape: (10, 224, 224, 3)\n",
            "Label Batch Shape: (10, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be13a81-f2fd-49ef-aa7f-2d29ab5dfa78",
      "metadata": {
        "id": "9be13a81-f2fd-49ef-aa7f-2d29ab5dfa78"
      },
      "source": [
        "## 4. CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e001153-dad0-498b-af1a-4dffb21927d9",
      "metadata": {
        "id": "0e001153-dad0-498b-af1a-4dffb21927d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2925d0-d945-49dc-9041-23e3efad28fa",
      "metadata": {
        "id": "3e2925d0-d945-49dc-9041-23e3efad28fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c351690e-0e68-411c-8cd4-d71561b3f0d1",
      "metadata": {
        "id": "c351690e-0e68-411c-8cd4-d71561b3f0d1"
      },
      "source": [
        "### Summary of Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8d38059-3f5e-451a-98de-b18b5ee0de83",
      "metadata": {
        "id": "b8d38059-3f5e-451a-98de-b18b5ee0de83"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4960148-ddd0-4559-8911-fd45133aded0",
      "metadata": {
        "id": "f4960148-ddd0-4559-8911-fd45133aded0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ff95ff82-0b8b-403f-b952-a05799e2566c",
      "metadata": {
        "id": "ff95ff82-0b8b-403f-b952-a05799e2566c"
      },
      "source": [
        "## 5. Insights and Key Findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5ea98e-2357-45ed-a658-84514f93ce3b",
      "metadata": {
        "id": "cb5ea98e-2357-45ed-a658-84514f93ce3b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa028e92-5e80-4a89-9e9d-ac905adec60e",
      "metadata": {
        "id": "fa028e92-5e80-4a89-9e9d-ac905adec60e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7f70328d-c190-4a44-add0-667c97ed67d1",
      "metadata": {
        "id": "7f70328d-c190-4a44-add0-667c97ed67d1"
      },
      "source": [
        "## 6. Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c09d7c-723f-459e-9c0c-37408dcf2df4",
      "metadata": {
        "id": "08c09d7c-723f-459e-9c0c-37408dcf2df4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}