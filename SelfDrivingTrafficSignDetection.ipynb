{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00639790-3c60-4f66-9ec3-25d4ee17eaec",
   "metadata": {},
   "source": [
    "# Self Driving Traffic Sign Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f876881-edf5-4099-8be5-d34a393877a8",
   "metadata": {},
   "source": [
    "Isaiah Jenkins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0dcbf3-c303-49ec-8187-7b44990b1ece",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "012b37ac-9efb-417e-a169-9011d90a605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n",
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Available devices:\", tf.config.list_physical_devices())\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0a8fe-01b0-4928-beba-1d32baf1ece0",
   "metadata": {},
   "source": [
    "## 1. About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d7748-5cd9-42ef-87bb-fe8ec7e2d567",
   "metadata": {},
   "source": [
    "1. a. Description\n",
    "\n",
    "Throughout this analysis we will explore Udacity's Self Driving dataset. This dataset consists of images for thousands of pedestrians, bikers, cars, and traffic lights. Although traffic light images are underrepresented in the dataset, the focus of the analysis will be based solely on traffic light images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bbf2e-d81b-458b-a2b1-ad6ecf906910",
   "metadata": {},
   "source": [
    "1. b. Data dictionary, 97,942 labels across 11 classes and 15,000 images, 1,720 null examples (images with no labels).\n",
    "\n",
    "Class Balance across images (labels in each image)\n",
    "\n",
    "* car - 64,399 - over represented\n",
    "* pedestrian - 10,806\n",
    "* trafficLight-Red - 6,870\n",
    "* trafficLight-Green - 5,465 - under represented\n",
    "* truck - 3,623 - under represented\n",
    "* trafficLight - 2,568 - under represented\n",
    "* biker - 1,864 - under represented\n",
    "* trafficLight-RedLeft - 1,751 - under represented\n",
    "* trafficLight-GreenLeft - 310 - under represented\n",
    "* trafficLight-Yellow - 272 - under represented\n",
    "* trafficLight-YellowLeft - 14 - under represented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba6629-daed-4c51-bd9f-dcea2b5d31f1",
   "metadata": {},
   "source": [
    "## 2. Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573536a5-7aa4-4a25-bcb8-b076bafa5eb3",
   "metadata": {},
   "source": [
    "Throughout this analysis, we will explore and build various deep learning convolutional neural network (CNN) architectures to detect traffic light signs, aiming to optimize accuracy and efficiency. Our objective is to compare different model variations, such as CNNs with different depths, pre-trained models, and data augmentation techniques, to determine the most effective approach. Potential challenges include handling variations in lighting conditions, occlusions, and small object sizes, which may impact detection performance. Additionally, dataset imbalances and misclassifications due to similar-looking traffic signs could introduce biases, requiring careful preprocessing and model tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70704988-df5d-414e-bb7b-a6e2ce582de2",
   "metadata": {},
   "source": [
    "## 3. Data Exploration, Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb591fe-c7b6-40ae-904c-a265459646e7",
   "metadata": {},
   "source": [
    "* Extract traffic sign & traffic light images from the dataset to help with computational efficiency.\n",
    "* Resize images to standardize dataset making it computationally efficient making it easier to analyze data.\n",
    "* Normalize pixel values (0-1 range) to help with generalization.\n",
    "* Augment data (rotation, brightness shifts, contrast changes) to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ec18e-6c27-4948-b9a7-bf600e68ae78",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca496251-ff93-4235-bffe-faef1cb98d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/export'\n",
    "CSV_PATH = os.path.join(DATASET_PATH, '_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f534363-2f7b-48d3-937d-2fa7a2c45a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH) # load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada1423d-de74-4699-9fd5-3d367983a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = df['filename'].values # image files names\n",
    "labels = df['class'].values # classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12586dcf-485e-4106-ae65-223e7f0d2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"trafficLight-Red\": 0, \"trafficLight-RedLeft\": 1, \"trafficLight_Yellow\": 2, \"trafficLight_YellowLeft\": 3, \"trafficLight-Green\": 4, \"trafficLight-GreenLeft\": 5 }  # Adjust based on dataset\n",
    "labels = [label_map[label] for label in labels if label in label_map]  # Convert text labels to integers\n",
    "labels = to_categorical(labels, num_classes=6)  # Convert to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f26a31-6e7e-49b1-b097-0a727da54e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7697debe-3e67-4398-9cd9-d17b10ab1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load & Preprocess Images\n",
    "def load_and_preprocess_image(file_name, label):\n",
    "    img_path = os.path.join(DATASET_PATH, file_name)  # Update image folder path\n",
    "    img = load_img(img_path, target_size=IMG_SIZE)  # Load & Resize Image\n",
    "    img = img_to_array(img) / 255.0  # Convert to NumPy array & Normalize (0-1)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d4c61e-4129-4780-a0fe-20b0f962c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load All Images\n",
    "image_data = [load_and_preprocess_image(f, l) for f, l in zip(file_names, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6fb4a01-fc25-4b4f-80c4-458dca3efb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 09:31:56.972049: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-02-12 09:31:56.972090: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-12 09:31:56.972104: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-02-12 09:31:56.972276: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-12 09:31:56.972296: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert to TensorFlow Dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mimage_data)\n\u001b[0;32m----> 3\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(labels, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Documents/IBM Cert Coursework/DeepLearningAndReinforcement/SelfDrivingTrafficSignDetection/env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/IBM Cert Coursework/DeepLearningAndReinforcement/SelfDrivingTrafficSignDetection/env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Convert to TensorFlow Dataset\n",
    "images, labels = zip(*image_data)\n",
    "images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7c5eef-5d56-4cfb-b00f-62435d762cc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions 224 and 6 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a tf.data Dataset for Training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/IBM Cert Coursework/DeepLearningAndReinforcement/SelfDrivingTrafficSignDetection/env/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:826\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IBM Cert Coursework/DeepLearningAndReinforcement/SelfDrivingTrafficSignDetection/env/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IBM Cert Coursework/DeepLearningAndReinforcement/SelfDrivingTrafficSignDetection/env/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:45\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     42\u001b[0m batch_dim \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mDimension(\n\u001b[1;32m     43\u001b[0m     tensor_shape\u001b[38;5;241m.\u001b[39mdimension_value(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_shape()[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m---> 45\u001b[0m   \u001b[43mbatch_dim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_is_compatible_with\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtensor_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDimension\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtensor_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimension_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mtensor_slice_dataset(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors,\n\u001b[1;32m     51\u001b[0m     output_shapes\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_shapes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure),\n\u001b[1;32m     52\u001b[0m     is_files\u001b[38;5;241m=\u001b[39mis_files,\n\u001b[1;32m     53\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mSerializeToString())\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[0;32m~/Documents/IBM Cert Coursework/DeepLearningAndReinforcement/SelfDrivingTrafficSignDetection/env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:303\u001b[0m, in \u001b[0;36mDimension.assert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raises an exception if `other` is not compatible with this Dimension.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    is_compatible_with).\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_compatible_with(other):\n\u001b[0;32m--> 303\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensions \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m are not compatible\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    304\u001b[0m                    (\u001b[38;5;28mself\u001b[39m, other))\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 224 and 6 are not compatible"
     ]
    }
   ],
   "source": [
    "# Create a tf.data Dataset for Training\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels)).batch(32).shuffle(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be13a81-f2fd-49ef-aa7f-2d29ab5dfa78",
   "metadata": {},
   "source": [
    "## 4. CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e001153-dad0-498b-af1a-4dffb21927d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2925d0-d945-49dc-9041-23e3efad28fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c351690e-0e68-411c-8cd4-d71561b3f0d1",
   "metadata": {},
   "source": [
    "### Summary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e24a1d-c7d7-4fc6-a8dc-ede7e8eac4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview Dataset\n",
    "for img_batch, label_batch in dataset.take(1):\n",
    "    print(f\"Image Batch Shape: {img_batch.shape}\")\n",
    "    print(f\"Label Batch Shape: {label_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d38059-3f5e-451a-98de-b18b5ee0de83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4960148-ddd0-4559-8911-fd45133aded0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff95ff82-0b8b-403f-b952-a05799e2566c",
   "metadata": {},
   "source": [
    "## 5. Insights and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ea98e-2357-45ed-a658-84514f93ce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa028e92-5e80-4a89-9e9d-ac905adec60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f70328d-c190-4a44-add0-667c97ed67d1",
   "metadata": {},
   "source": [
    "## 6. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c09d7c-723f-459e-9c0c-37408dcf2df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
